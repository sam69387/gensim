{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial on Keras",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sam69387/gensim/blob/master/Tutorial_on_Keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "lFdrXDx7fhCS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tutorial on Neural Networks using Keras\n",
        "**Keras** is a powerful Python tool to develop and evaluate deep neural networks. It wraps the efficient numerical computation libraries Theano and TensorFlow and allows you to define and train neural network models in a few short lines of code."
      ]
    },
    {
      "metadata": {
        "id": "MzVZKi_uf6hl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Steps\n",
        "\n",
        "Here are the basic steps to be followed while implementing a deep neural network. \n",
        "\n",
        "1.   Load Data\n",
        "2.   Define Model\n",
        "3.   Compile Model\n",
        "4.   Fit Model\n",
        "5.   Evaluate Model\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "U7xfm9sKgpN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install Keras and Import packages"
      ]
    },
    {
      "metadata": {
        "id": "6egvOBk1fbhV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mrVAcTzThMHO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Data\n",
        "For this tutorial, we will be using the default IMDB data that comes pre-loaded into Keras."
      ]
    },
    {
      "metadata": {
        "id": "q8hUJI9Agz7h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwbxKeEkho38",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define Model\n",
        "Here we define the Neural Network. We specify input dimensions, number of hidden layers, size of each layer, etc."
      ]
    },
    {
      "metadata": {
        "id": "a5Kw7KdYhpI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_review_length = 10\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=10, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPZgpxIoif5_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compile Model\n",
        "Specify the loss function, optimizer to be used and evaluation metrics."
      ]
    },
    {
      "metadata": {
        "id": "fsLmjn-0iitu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gLSnGadkijC7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fit Model\n",
        "Here we fit the model to the training set. Specify number of epochs. "
      ]
    },
    {
      "metadata": {
        "id": "ypWkJacoioFs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qMSVM1lyFZA_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model\n",
        "Calculate accuracy metrics."
      ]
    },
    {
      "metadata": {
        "id": "zvG2yZz6FgB-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vRtjyODhGnup",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "Now we begin with the actual stuff for the RNN assignment. We will now use the data from Assistments data set. This is the data set you will be using for your assignment. Here are the helper preprocessing functions. "
      ]
    },
    {
      "metadata": {
        "id": "T430QBnnKU8A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To upload the files into colab, the best option is to upload them in a GitHub Repo and then clone that repo. You can use my repo, because **I am a good person.**"
      ]
    },
    {
      "metadata": {
        "id": "50m4PSGoGy-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rvoak/RNN_DKT\n",
        "%cd RNN_DKT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIkmbJqsK86r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "response_df = pd.read_csv('correct.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
        "skill_df = pd.read_csv('skill.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
        "assistment_df = pd.read_csv('assistment_id.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
        "skill_dict = {}\n",
        "with open('skill_dict.json', 'r', encoding='utf-8') as f:\n",
        "    loaded = json.load(f)\n",
        "    for k, v in loaded.items():\n",
        "        skill_dict[k] = int(v)\n",
        "\n",
        "skill_num = len(skill_dict) + 1 # including 0\n",
        "\n",
        "def one_hot(skill_matrix, vocab_size):\n",
        "    '''\n",
        "    params:\n",
        "        skill_matrix: 2-D matrix (student, skills)\n",
        "        vocab_size: size of the vocabulary\n",
        "    returns:\n",
        "        a ndarray with a shape like (student, sequence_len, vocab_size)\n",
        "    '''\n",
        "    seq_len = skill_matrix.shape[1]\n",
        "    result = np.zeros((skill_matrix.shape[0], seq_len, vocab_size))\n",
        "    for i in range(skill_matrix.shape[0]):\n",
        "        result[i, np.arange(seq_len), skill_matrix[i]] = 1.\n",
        "    return result\n",
        "\n",
        "def dkt_one_hot(skill_matrix, response_matrix, vocab_size):\n",
        "    seq_len = skill_matrix.shape[1]\n",
        "    skill_response_array = np.zeros((skill_matrix.shape[0], seq_len, 2 * vocab_size))\n",
        "    for i in range(skill_matrix.shape[0]):\n",
        "        skill_response_array[i, np.arange(seq_len), 2 * skill_matrix[i] + response_matrix[i]] = 1.\n",
        "    return skill_response_array\n",
        "\n",
        "def preprocess(skill_df, response_df, skill_num):\n",
        "    skill_matrix = skill_df.iloc[:, 1:].values\n",
        "    response_array = response_df.iloc[:, 1:].values\n",
        "    skill_array = one_hot(skill_matrix, skill_num)\n",
        "    skill_response_array = dkt_one_hot(skill_matrix, response_array, skill_num)\n",
        "    return skill_array, response_array, skill_response_array\n",
        "    \n",
        "\n",
        "skill_array, response_array, skill_response_array = preprocess(skill_df, response_df, skill_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gReJpkj0LOf4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Building\n",
        "Functions to build the models."
      ]
    },
    {
      "metadata": {
        "id": "FvCK9w1GLCS1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense, LSTM, TimeDistributed, Lambda, multiply\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import backend as K\n",
        "import os\n",
        "from importlib import reload\n",
        "\n",
        "def set_keras_backend(backend):\n",
        "\n",
        "    if K.backend() != backend:\n",
        "        os.environ['KERAS_BACKEND'] = backend\n",
        "        reload(K)\n",
        "        assert K.backend() == backend\n",
        "\n",
        "set_keras_backend(\"theano\")\n",
        "\n",
        "def build_skill2skill_model(input_shape, lstm_dim=32, dropout=0.0):\n",
        "    input = Input(shape=input_shape, name='input_skills')\n",
        "    lstm = LSTM(lstm_dim, \n",
        "                return_sequences=True, \n",
        "                dropout=dropout,\n",
        "                name='lstm_layer')(input)\n",
        "    output = TimeDistributed(Dense(input_shape[-1], activation='softmax'), name='probability')(lstm)\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0)\n",
        "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def reduce_dim(x):\n",
        "    x = K.max(x, axis=-1, keepdims=True)\n",
        "    return x\n",
        "\n",
        "def build_dkt_model(input_shape, lstm_dim=32, dropout=0.0):\n",
        "    input_skills = Input(shape=input_shape, name='input_skills')\n",
        "    lstm = LSTM(lstm_dim, \n",
        "                return_sequences=True, \n",
        "                dropout=dropout,\n",
        "                name='lstm_layer')(input_skills)\n",
        "    dense = TimeDistributed(Dense(int(input_shape[-1]/2), activation='sigmoid'), name='probability_for_each')(lstm)\n",
        "    \n",
        "    skill_next = Input(shape=(input_shape[0], int(input_shape[1]/2)), name='next_skill_tested')\n",
        "    merged = multiply([dense, skill_next], name='multiply')\n",
        "    reduced = Lambda(reduce_dim, output_shape=(input_shape[0], 1), name='reduce_dim')(merged)\n",
        "    \n",
        "    model = Model(inputs=[input_skills, skill_next], outputs=[reduced])\n",
        "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0)\n",
        "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "print('skill2skill')\n",
        "skill2skill_model = build_skill2skill_model((99, skill_num), lstm_dim=64)\n",
        "\n",
        "print('dkt')\n",
        "dkt_model = build_dkt_model((99, 2 * skill_num), lstm_dim=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7g2nxjL5LXKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}